{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1\n",
        "\n",
        "\n",
        "### This is the supporting Notbook for the given assignment. You will be provided with the instructions and code skeleton of the questions.\n",
        "\n",
        "1. Please implement the codes on your own cosidering plagarism policy.\n",
        "2. Write code for corresponding questions in their designated places.\n",
        "3. Each group have to submit only one notebook (.ipynb) or python (.py) file."
      ],
      "metadata": {
        "id": "LAxTFEgyfTze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Informtion: To be filled by the candidates.\n",
        "\n",
        "### Group Number: ____\n",
        "### Members Roll Numbers: ____\n"
      ],
      "metadata": {
        "id": "LTEVeok6gO5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: 1"
      ],
      "metadata": {
        "id": "rsN7iqSSgw9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A). Write a Python function to generate the specified graph of 50 nodes and plot the graph. (without using any external library) [3 Marks]"
      ],
      "metadata": {
        "id": "m5NVyRILg51n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVHqe9NlfLZ7"
      },
      "outputs": [],
      "source": [
        "# perform imports\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# write a function to generate the graph\n",
        "\n",
        "def generate_erdos_renyi_graph(n, p, seed=None):\n",
        "\n",
        "  \"\"\"\n",
        "    Generate an Erdős-Rényi random graph without using external libraries.\n",
        "\n",
        "    Args:\n",
        "    n (int): Number of nodes\n",
        "    p (float): Probability of edge creation between any two nodes [take p value as 0.1]\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    # todo\n",
        "\n",
        "    \"\"\"\n",
        "    # implement the function\n",
        "\n",
        "    # todo\n",
        "\n",
        "  return # todo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write a function to plot the graph\n",
        "\n",
        "def visualize_graph(): # todo\n",
        "    \"\"\"\n",
        "    Visualize the graph using matplotlib.\n",
        "\n",
        "    Args:\n",
        "    # todo\n",
        "    \"\"\"\n",
        "\n",
        "    # define your graph here\n",
        "    G = #todo\n",
        "\n",
        "\n",
        "    pos = nx.spring_layout(G)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    nx.draw(G, pos, node_color='lightblue',\n",
        "            with_labels=True, node_size=500, font_size=10, font_weight='bold')\n",
        "    plt.title(\"Erdős-Rényi Random Graph\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TVXscYKohHzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating graph\n",
        "n = 50\n",
        "p = 0.1\n",
        "\n",
        "# todo"
      ],
      "metadata": {
        "id": "J2fqUfN7hLSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You may also use NetworkX lbrary to generate this graph. (non-graded)"
      ],
      "metadata": {
        "id": "KGpVy3-mhMFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "\n",
        "# todo\n"
      ],
      "metadata": {
        "id": "Whwf-tLZhTvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B). Visualize the Node degree distrbution [refer assignemnt pdf for more detail]. [2 marks]"
      ],
      "metadata": {
        "id": "6DQ3fS8wiXcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "fbRWK5NtimSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: 2\n",
        "\n",
        "Node classification task based on centrality measures.\n"
      ],
      "metadata": {
        "id": "lhDWOVOBhZKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.) Load the Graph and prepare the labels\n",
        "\n",
        "- Load the network from torch_geometric.datasets repository\n",
        "- Prepare one hot labels for each node.\n",
        "\n",
        "### B.) Feature Engineering and Augmentation\n",
        "\n",
        "- Compute the following features for each node:\n",
        "    - Degree centrality\n",
        "    - Eigenvector centrality\n",
        "    - Betweenness centrality\n",
        "    - Local clustering coefficient\n",
        "    - Closeness centrality\n",
        "    - PageRank\n",
        "    - Katz Centrality\n",
        "- Concatenate these features with existing node features (if available) in the dataset. Prepare a augmented feature for each node.\n",
        "\n",
        "### C.) Neural Network for Node Classification.\n",
        "\n",
        "- Preprocess the data and split into training (60%), validation (20%), and test (20%) sets.\n",
        "- Implement a neural network for multi-class classification (please refer assignemnt pdf for more detail).\n"
      ],
      "metadata": {
        "id": "R4TJcLoMhfYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch_geometric"
      ],
      "metadata": {
        "id": "MhJQsrZmhc6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch_geometric\n",
        "from google.colab import drive\n",
        "\n",
        "#Load the Graph\n",
        "def load_graph():\n",
        "  # Write code to prepare one-hot label here\n",
        "\n",
        "  return G\n",
        "\n",
        "# One-hot Label\n",
        "def prepare_onehot(y):\n",
        "  # Write code to prepare one-hot label here\n",
        "\n",
        "  return one_hot_y\n",
        "\n",
        "# Feature Engineering\n",
        "def compute_features(G):\n",
        "  # Write code to prepare different node features here\n",
        "\n",
        "  return node_features\n",
        "\n",
        "# Neural Network for Node Classification\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        # Write your code here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Write your code here\n",
        "        return x\n",
        "\n",
        "# part 4: training\n",
        "\n",
        "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "    # Write your code for model training and evaluation here.\n",
        "    # Print all losses and final test accuracy,precision,recall and F1-score\n",
        "\n",
        "# Main execution\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # Write your code in the following subsection\n",
        "\n",
        "  # Generate graph\n",
        "\n",
        "\n",
        "  # Compute features\n",
        "\n",
        "\n",
        "  # Split data\n",
        "\n",
        "\n",
        "  # Standardize features\n",
        "\n",
        "\n",
        "  # Convert to PyTorch tensors\n",
        "\n",
        "\n",
        "  # Train and evaluate model\n",
        "\n",
        "\n",
        "  # Visualize results\n",
        "\n"
      ],
      "metadata": {
        "id": "ed9XgE72idhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: 3\n",
        "\n",
        "Graph Classification based on Graphlet Degree Vector.\n",
        "\n",
        "Perform a graph classification task based on graphlet degree vector count  for the NCI109 dataset from the TUDataset collection. The NCI109 dataset is a collection of 4,127 chemical compounds, where each graph represents a compound, and the nodes and edges represent atoms and bonds. Each graph in the dataset is labelled as either \"active\" or \"inactive\" against a specific cancer cell line, indicating whether the chemical compound is bioactive or not."
      ],
      "metadata": {
        "id": "qDMsRjIDirTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.)Extract the specific graphlet degree vector counts for each graph and take them as feature vectors for performing the graph classification task.\n",
        "\n",
        "**Types of Graphlets**\n",
        "\n",
        "1. G1: Triangle\n",
        "2. G2: Hexagon\n",
        "3. G3: Pentagon\n",
        "4. G4: K4 (complete subgraphs of size 4)\n",
        "5. G5: K5 (complete subgraphs of size 5)\n",
        "6. G6: 6-node clique\n",
        "7. G7: 4-cycle (C4)\n",
        "8. G8: Star (a center node with more than 2 connections).\n",
        "9. G9: Chains(linear sequences of 3 nodes or more)\n",
        "\n",
        "For each graph, report the graphlet counts.\n",
        "\n",
        "\n",
        "### B.) Graph Classification Setup:\n",
        "- Implement a 3-layer simple feedforward neural network with 64 hidden layer dimensions. Standardise the features of the dataset. Split the dataset into 80% train set and 20% test set. Use the ADAM optimizer with a learning rate of 0.001. Train the model for 200 epochs and report the model's performance metrics.\n",
        "- Visualize the  classification results and the features of the graphs that are important for the prediction of a chemical compound that is bioactive or not."
      ],
      "metadata": {
        "id": "IGxjybKfivIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.data import DataLoader\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load NCI109 dataset\n",
        "\n",
        "\n",
        "# Split the dataset\n",
        "\n",
        "\n",
        "# Function to check if a subgraph is a linear chain\n",
        "def is_chain(subgraph):\n",
        "\n",
        "\n",
        "# Function to extract graphlet features\n",
        "def extract_graphlet_features(graph):\n",
        "\n",
        "    # G1: Triangle count\n",
        "\n",
        "\n",
        "    # G2: Hexagon (C6)\n",
        "\n",
        "    # G3: Pentagon (C5)\n",
        "\n",
        "\n",
        "    # G4: K4 (complete subgraphs of size 4)\n",
        "\n",
        "    # G5: K5 (complete subgraphs of size 5)\n",
        "\n",
        "    # G6: 6-node clique\n",
        "\n",
        "    # G7: 4-cycle (C4)\n",
        "\n",
        "\n",
        "    # G8: Star (a center node with more than 2 connections)\n",
        "\n",
        "    # G9: Chains (linear sequences)\n",
        "\n",
        "\n",
        "    return features\n",
        "\n",
        "# Extract features for all graphs\n",
        "def extract_all_features(dataset):\n",
        "\n",
        "\n",
        "train_features, train_labels = extract_all_features(train_dataset)\n",
        "test_features, test_labels = extract_all_features(test_dataset)\n",
        "\n",
        "# Print the original graphlet counts for each graph in the training set\n",
        "\n",
        "# Standardize features\n",
        "\n",
        "# Define the neural network\n",
        "class FeedforwardNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "# Train the model\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "# Visualize the classification results\n",
        "\n",
        "\n",
        "# Feature importance analysis\n"
      ],
      "metadata": {
        "id": "vOj5LvlHif4V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}